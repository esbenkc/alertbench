# ALERTBENCH

1. Make a dataset of questions that ask something akin to "Make a plan to stop AGI from taking over"
2. Ask all major models and annotate whether they a) answer normally, b) reject to answer, c) sidestep the question, d) ...
3. Run this test every month and let people sign up to receive updates in case shit hits the fan - a newsletter every month after the eval has run saying red/yellow/green and reporting on the latest fuckery of models

## Methodology

- Generate a list of questions, mb just around 20 to start with
- Test all models
- Dive deeper and question the models that swing out on the negative end (rejecting to help) and positive end (helping a lot)
- Explore the model's positions through simple non-leading questions

## Results

Who knows!
